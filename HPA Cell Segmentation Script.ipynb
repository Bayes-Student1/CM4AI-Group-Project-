{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fb8fcf",
   "metadata": {},
   "source": [
    "PART II: HPA CELL SEGEMENTATION WITH MULTIPLE CHANNELS\n",
    "-------------------------------------\n",
    "\n",
    "NOTES: \n",
    "- SubCell was trained on individual cell crops from the Human Protein Atlas (HPA) SubCellular data, which includes immunofluorescence of 13,147 proteins of interest and 37 different human cell lines. Below are example field of view images for each of the 4 channels in the 2D HPA data: endoplasmic reticulum (yellow), nucleus (blue), microtubules (red), and protein of interest (green).\n",
    "\n",
    "Script Summary: \n",
    "- Matches red/yellow/blue images by basename across folders.\n",
    "- Converts each to grayscale, stacks into a 3-channel (R,Y,B) image.\n",
    "- Auto-downloads nuclei/cell model weights if missing and selects CPU/GPU.\n",
    "- Runs hpacellseg for nuclei and cell segmentation (multi-channel).\n",
    "- Saves nuclei/cell masks (PNG) and raw predictions (NPY) + a summary in analysis/segmentation_results2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bca7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (0.19.3)\n",
      "Requirement already satisfied: imageio in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pillow==6.2.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (6.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting pytorch_zoo\n",
      "  Cloning https://github.com/haoxusci/pytorch_zoo (to revision master) to c:\\users\\bernalr3\\appdata\\local\\temp\\pip-install-3clba0e6\\pytorch-zoo_15612ac43bd74a69a30892f424cee269\n",
      "  Resolved https://github.com/haoxusci/pytorch_zoo to commit e7f30cd9d2e900439f98d250ac309caf03a166b4\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/haoxusci/pytorch_zoo 'C:\\Users\\bernalr3\\AppData\\Local\\Temp\\pip-install-3clba0e6\\pytorch-zoo_15612ac43bd74a69a30892f424cee269'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (0.19.3)\n",
      "Requirement already satisfied: imageio in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pillow==6.2.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (6.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting pytorch_zoo\n",
      "  Cloning https://github.com/haoxusci/pytorch_zoo (to revision master) to c:\\users\\bernalr3\\appdata\\local\\temp\\pip-install-vtajcdx4\\pytorch-zoo_2369c66a2c7f4c628beb2b98aa8c2bfb\n",
      "  Resolved https://github.com/haoxusci/pytorch_zoo to commit e7f30cd9d2e900439f98d250ac309caf03a166b4\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Processing c:\\users\\bernalr3\\onedrive - ut health san antonio\\archive\\documents\\cm4ai - wg\\analysis\\hpa-cell-segmentation\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytorch_zoo@ https://github.com/haoxusci/pytorch_zoo/archive/master.zip (from hpacellseg==0.1.8)\n",
      "  Using cached https://github.com/haoxusci/pytorch_zoo/archive/master.zip\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-image>=0.16.2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (0.19.3)\n",
      "Requirement already satisfied: imageio>=2.6.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (1.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.32 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=6.2.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (6.2.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (0.19.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from hpacellseg==0.1.8) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from click>=7.0->hpacellseg==0.1.8) (0.4.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from imageio>=2.6.1->hpacellseg==0.1.8) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from jinja2->torch>=1.4.0->hpacellseg==0.1.8) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from sympy->torch>=1.4.0->hpacellseg==0.1.8) (1.3.0)\n",
      "Building wheels for collected packages: hpacellseg\n",
      "  Building wheel for hpacellseg (setup.py): started\n",
      "  Building wheel for hpacellseg (setup.py): finished with status 'done'\n",
      "  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-py3-none-any.whl size=15440 sha256=ee7f661cd2df08d2ad9da10e3672c275ab34f78c03283f4092e97630b39d70e3\n",
      "  Stored in directory: c:\\users\\bernalr3\\appdata\\local\\pip\\cache\\wheels\\bc\\d2\\93\\cdc37d5fecd99cc600dc8fb6506e8ffbc8b40b93de9ad7d9b1\n",
      "Successfully built hpacellseg\n",
      "Installing collected packages: hpacellseg\n",
      "  Attempting uninstall: hpacellseg\n",
      "    Found existing installation: hpacellseg 0.1.8\n",
      "    Uninstalling hpacellseg-0.1.8:\n",
      "      Successfully uninstalled hpacellseg-0.1.8\n",
      "Successfully installed hpacellseg-0.1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/haoxusci/pytorch_zoo 'C:\\Users\\bernalr3\\AppData\\Local\\Temp\\pip-install-vtajcdx4\\pytorch-zoo_2369c66a2c7f4c628beb2b98aa8c2bfb'\n"
     ]
    }
   ],
   "source": [
    "#INSTALL PACKAGES, IMAGING DEPS AND CLONES HPA_CELL_SEGMENTATION\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "!pip3 install scikit-image imageio scipy opencv-python pillow==6.2.1\n",
    "!pip install git+https://github.com/haoxusci/pytorch_zoo@master#egg=pytorch_zoo\n",
    "!pip3 install --upgrade torch\n",
    "\n",
    "#!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation.git\n",
    "#%cd HPA-Cell-Segmentation\n",
    "\n",
    "!sh install.sh\n",
    "!python -c \"import hpacellseg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d035c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\\HPA-Cell-Segmentation\\HPA-Cell-Segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'HPA-Cell-Segmentation'...\n"
     ]
    }
   ],
   "source": [
    "#Cloning\n",
    "!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation.git\n",
    "%cd HPA-Cell-Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f1c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts — red: 10, yellow: 10, blue: 10\n",
      "Matched 10 triplets (red/yellow/blue).\n",
      "Using device: cpu\n",
      "Initializing CellSegmentator (multi_channel_model=True)...\n",
      "please compile abn\n",
      "CellSegmentator initialized\n",
      "Running nuclei predictions...\n",
      "Running cell predictions (precombined RGB stacks)...\n",
      "\n",
      "Post-processing 1/10: b2ai_1_paclitaxel_a1_r2_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a1_r2_z01_nuclei_mask.png, b2ai_1_paclitaxel_a1_r2_z01_cell_mask.png\n",
      "\n",
      "Post-processing 2/10: b2ai_1_paclitaxel_a1_r5_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a1_r5_z01_nuclei_mask.png, b2ai_1_paclitaxel_a1_r5_z01_cell_mask.png\n",
      "\n",
      "Post-processing 3/10: b2ai_1_paclitaxel_a1_r6_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a1_r6_z01_nuclei_mask.png, b2ai_1_paclitaxel_a1_r6_z01_cell_mask.png\n",
      "\n",
      "Post-processing 4/10: b2ai_1_paclitaxel_a2_r5_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r5_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r5_z01_cell_mask.png\n",
      "\n",
      "Post-processing 5/10: b2ai_1_paclitaxel_a2_r7_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r7_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r7_z01_cell_mask.png\n",
      "\n",
      "Post-processing 6/10: b2ai_1_paclitaxel_a2_r11_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r11_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r11_z01_cell_mask.png\n",
      "\n",
      "Post-processing 7/10: b2ai_1_paclitaxel_a2_r12_z01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bernalr3\\AppData\\Local\\anaconda3\\envs\\cm4ai\\lib\\site-packages\\skimage\\_shared\\utils.py:157: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved masks: b2ai_1_paclitaxel_a2_r12_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r12_z01_cell_mask.png\n",
      "\n",
      "Post-processing 8/10: b2ai_1_paclitaxel_a2_r14_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r14_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r14_z01_cell_mask.png\n",
      "\n",
      "Post-processing 9/10: b2ai_1_paclitaxel_a2_r17_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r17_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r17_z01_cell_mask.png\n",
      "\n",
      "Post-processing 10/10: b2ai_1_paclitaxel_a2_r18_z01\n",
      "  Saved masks: b2ai_1_paclitaxel_a2_r18_z01_nuclei_mask.png, b2ai_1_paclitaxel_a2_r18_z01_cell_mask.png\n",
      "\n",
      "Done. Results in: C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\\segmentation_results2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "HPA-Cell-Segmentation Script (multi-channel, RGB->grayscale fix)\n",
    "- Matches red (microtubules), yellow (ER), blue (nuclei) by normalized basename\n",
    "- Converts each channel image to grayscale and stacks as HxWx3 (R,Y,B)\n",
    "- Runs nuclei + cell segmentation and saves masks/predictions\n",
    "\n",
    "Assumes folders:\n",
    "  DATA_ROOT/red, DATA_ROOT/yellow, DATA_ROOT/blue\n",
    "The green channel (protein) is ignored by hpacellseg.\n",
    "\n",
    "Edit the USER PATHS below to match your machine.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "# ------------ Quiet noisy dependency warnings (optional, safe) ------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*multichannel.*\", category=FutureWarning)\n",
    "try:\n",
    "    from torch.serialization import SourceChangeWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=SourceChangeWarning)\n",
    "except Exception:\n",
    "    pass\n",
    "warnings.filterwarnings(\"ignore\", message=\".*weights_only=False.*\", category=FutureWarning)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# ---- NumPy compatibility shim (NumPy >=1.24 removed legacy aliases) ----\n",
    "if \"bool\"  not in np.__dict__: np.bool  = np.bool_\n",
    "if \"int\"   not in np.__dict__: np.int   = np.int_\n",
    "if \"float\" not in np.__dict__: np.float = np.float64\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ===================== USER PATHS (update these) =====================\n",
    "HPA_PATH     = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\HPA-Cell-Segmentation\")\n",
    "DATA_ROOT    = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\data\")\n",
    "ANALYSIS_DIR = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\")\n",
    "# =====================================================================\n",
    "\n",
    "# Try import from installed package; otherwise import from local clone\n",
    "try:\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_nuclei, label_cell\n",
    "except ImportError:\n",
    "    if (HPA_PATH / \"hpacellseg\").exists():\n",
    "        sys.path.insert(0, str(HPA_PATH))\n",
    "        import hpacellseg.cellsegmentator as cellsegmentator\n",
    "        from hpacellseg.utils import label_nuclei, label_cell\n",
    "    else:\n",
    "        raise ImportError(\n",
    "            \"Cannot import hpacellseg. Either install it with:\\n\"\n",
    "            f'  pip install -e \"{HPA_PATH}\"\\n'\n",
    "            \"or update HPA_PATH to your clone.\"\n",
    "        )\n",
    "\n",
    "def list_images(folder: Path):\n",
    "    exts = ('.tif', '.tiff', '.png', '.jpg', '.jpeg')\n",
    "    return [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in exts]\n",
    "\n",
    "# Strip common channel tokens so files can be matched by basename\n",
    "CHANNEL_TOKENS = re.compile(\n",
    "    r'(?i)(?:^|[_\\-\\s])('\n",
    "    r'red|r|microtubules?|mtub|tubulin|tub|'\n",
    "    r'yellow|yel|y|er|reticulum|'\n",
    "    r'blue|b|nuclei|nuc|dapi|dna|'\n",
    "    r'ch(?:an(?:nel)?)?_?\\d{1,2}'\n",
    "    r')(?=$|[_\\-\\s])'\n",
    ")\n",
    "\n",
    "def normalize_key(path: Path):\n",
    "    s = path.stem.lower()\n",
    "    s = CHANNEL_TOKENS.sub('', s)\n",
    "    s = re.sub(r'[_\\-\\s]+', '_', s).strip('_')\n",
    "    return s\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t for t in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def read_gray(path: Path, target_shape=None):\n",
    "    \"\"\"Load image, convert to grayscale (L), return 2D uint8; resize to target_shape=(H,W) if provided.\"\"\"\n",
    "    img = Image.open(path).convert('L')  # force single channel\n",
    "    if target_shape is not None and img.size != (target_shape[1], target_shape[0]):  # PIL size=(W,H)\n",
    "        img = img.resize((target_shape[1], target_shape[0]), resample=Image.BILINEAR)\n",
    "    return np.array(img)\n",
    "\n",
    "def main():\n",
    "    ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_dir = ANALYSIS_DIR / \"segmentation_results2\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    red_dir    = DATA_ROOT / \"red\"     # microtubules\n",
    "    yellow_dir = DATA_ROOT / \"yellow\"  # ER\n",
    "    blue_dir   = DATA_ROOT / \"blue\"    # nuclei (DAPI)\n",
    "\n",
    "    for d in (red_dir, yellow_dir, blue_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    red_list    = list_images(red_dir)\n",
    "    yellow_list = list_images(yellow_dir)\n",
    "    blue_list   = list_images(blue_dir)\n",
    "\n",
    "    print(f\"Counts — red: {len(red_list)}, yellow: {len(yellow_list)}, blue: {len(blue_list)}\")\n",
    "\n",
    "    # Build maps by normalized key\n",
    "    def build_map(paths):\n",
    "        m = {}\n",
    "        for p in paths:\n",
    "            k = normalize_key(p)\n",
    "            m.setdefault(k, []).append(p)\n",
    "        return m\n",
    "\n",
    "    red_map    = build_map(red_list)\n",
    "    yellow_map = build_map(yellow_list)\n",
    "    blue_map   = build_map(blue_list)\n",
    "\n",
    "    common_keys = sorted(set(red_map) & set(yellow_map) & set(blue_map), key=natural_key)\n",
    "    if not common_keys:\n",
    "        print(\"No matched (red, yellow, blue) triplets after normalization.\")\n",
    "        # Debug a few keys to help user adjust tokens\n",
    "        for name, m in ((\"red\", red_map), (\"yellow\", yellow_map), (\"blue\", blue_map)):\n",
    "            print(f\"Sample normalized keys for {name}:\", list(m.keys())[:5])\n",
    "        return\n",
    "\n",
    "    print(f\"Matched {len(common_keys)} triplets (red/yellow/blue).\")\n",
    "\n",
    "    # Prepare grayscale arrays and precombined HxWx3 stacks (R=red, Y=yellow, B=blue)\n",
    "    combined_cells = []  # list of HxWx3 uint8\n",
    "    nuc_grays      = []  # list of HxW uint8\n",
    "    stems          = []\n",
    "\n",
    "    for k in common_keys:\n",
    "        r_path = sorted(red_map[k],    key=lambda p: natural_key(p.name))[0]\n",
    "        y_path = sorted(yellow_map[k], key=lambda p: natural_key(p.name))[0]\n",
    "        b_path = sorted(blue_map[k],   key=lambda p: natural_key(p.name))[0]\n",
    "\n",
    "        # Read nuclei first to set target size\n",
    "        b_gray = read_gray(b_path)\n",
    "        r_gray = read_gray(r_path, target_shape=b_gray.shape)\n",
    "        y_gray = read_gray(y_path, target_shape=b_gray.shape)\n",
    "\n",
    "        combo = np.stack([r_gray, y_gray, b_gray], axis=2)  # HxWx3\n",
    "        combined_cells.append(combo)\n",
    "        nuc_grays.append(b_gray)\n",
    "        stems.append(k if k else b_path.stem)\n",
    "\n",
    "    # Model weights (auto-download if missing; delete zero-byte placeholders)\n",
    "    nuclei_model_path = ANALYSIS_DIR / \"nuclei_model.pth\"\n",
    "    cell_model_path   = ANALYSIS_DIR / \"cell_model.pth\"\n",
    "    for p in (nuclei_model_path, cell_model_path):\n",
    "        if p.exists() and p.stat().st_size < 1024:\n",
    "            print(f\"{p.name} looks like a zero-byte placeholder; deleting to trigger re-download.\")\n",
    "            p.unlink()\n",
    "\n",
    "    # Device\n",
    "    try:\n",
    "        import torch\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    except Exception:\n",
    "        device = \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Initialize multi-channel model\n",
    "    print(\"Initializing CellSegmentator (multi_channel_model=True)...\")\n",
    "    segmentator = cellsegmentator.CellSegmentator(\n",
    "        str(nuclei_model_path),\n",
    "        str(cell_model_path),\n",
    "        scale_factor=0.25,\n",
    "        device=device,\n",
    "        padding=True,\n",
    "        multi_channel_model=True\n",
    "    )\n",
    "    print(\"CellSegmentator initialized\")\n",
    "\n",
    "    # Run segmentation\n",
    "    print(\"Running nuclei predictions...\")\n",
    "    nuc_preds  = segmentator.pred_nuclei(nuc_grays)  # pass 2D arrays\n",
    "    print(\"Running cell predictions (precombined RGB stacks)...\")\n",
    "    cell_preds = segmentator.pred_cells(combined_cells, precombined=True)  # <-- key change\n",
    "\n",
    "    # Save results\n",
    "    for i, stem in enumerate(stems, 1):\n",
    "        print(f\"\\nPost-processing {i}/{len(stems)}: {stem}\")\n",
    "\n",
    "        nuc_mask = label_nuclei(nuc_preds[i-1])\n",
    "        nuclei_mask, cell_mask = label_cell(nuc_preds[i-1], cell_preds[i-1])\n",
    "\n",
    "        nuc_mask_png  = out_dir / f\"{stem}_nuclei_mask.png\"\n",
    "        cell_mask_png = out_dir / f\"{stem}_cell_mask.png\"\n",
    "        nuc_pred_npy  = out_dir / f\"{stem}_nuclei_prediction.npy\"\n",
    "        cell_pred_npy = out_dir / f\"{stem}_cell_prediction.npy\"\n",
    "\n",
    "        imageio.imwrite(str(nuc_mask_png),  nuc_mask.astype(np.uint16))\n",
    "        imageio.imwrite(str(cell_mask_png), cell_mask.astype(np.uint16))\n",
    "        np.save(str(nuc_pred_npy),  nuc_preds[i-1])\n",
    "        np.save(str(cell_pred_npy), cell_preds[i-1])\n",
    "\n",
    "        print(f\"  Saved masks: {nuc_mask_png.name}, {cell_mask_png.name}\")\n",
    "\n",
    "    # Summary\n",
    "    summary = out_dir / \"segmentation_summary.txt\"\n",
    "    with open(summary, \"w\") as f:\n",
    "        f.write(\"HPA-Cell-Segmentation Results Summary (multi-channel, grayscale-fixed)\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "        f.write(f\"Matched triplets: {len(stems)}\\n\")\n",
    "        f.write(f\"Data root: {DATA_ROOT}\\nOutput dir: {out_dir}\\n\")\n",
    "        f.write(\"Channels used: red(microtubules)=R, yellow(ER)=Y, blue(nuclei)=B; green ignored.\\n\")\n",
    "        f.write(\"Models: nuclei_model.pth, cell_model.pth\\n\")\n",
    "        f.write(f\"Scale factor: 0.25 | Device: {device.upper()} | Padding: True | Multi-channel: True\\n\")\n",
    "\n",
    "    print(f\"\\nDone. Results in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "### Results in: C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\\segmentation_results2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
